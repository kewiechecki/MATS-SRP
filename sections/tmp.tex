\documentclass{article}

% ... [previous content] ...

\begin{enumerate} 
\item \paragraph{Universality implies some ontologies are more ``natural'' than others.}
  If reasoning about diverse datasets leads to similar ontologies, this suggests some ontological structures are inherently more efficient or ``natural''.
  \item \paragraph{Implications for alignment}
      This notion of ``natural'' ontologies could significantly impact our alignment strategies, particularly in identifying and aligning around universally recognized concepts.
\end{enumerate}
%Mechinterp has had a fair bit of success on weak models, but we don't know how to make insights generalize to powerful models.

\section{Theory of Change}
I aim to address the problems of how to
\begin{enumerate}
  \item formalize the notion of a model's latent concept space
  \item distill a model's latent concept space
  \item enforce decomposability of latent concept space
  \item enforce robustness of existing concepts as the dimensionality of the latent concept space increases
\end{enumerate}
  
My justification for this line of research is
\begin{enumerate}
\item Almost every alignment proposal is limited by the ability to point at a concept.
\item According to singular learning theory, any sufficiently parameterized model trained on the same data will converge on the same latent representation of the data.
\item Mechinterp has made significant advances in identifying and characterizing specific features of interest, but mapping the entire feature space of existing frontier models is intractable.
\item Almost every alignment proposal becomes much more tractable if we can reason about features in isolation.
\end{enumerate}

Suppose we can locate a desirable concept in a model's ontology. This could be 
\subsection{A theoretical model of ontology}

Rapid progress in scaling LLMs has made it increasingly clear that data rather than compute is the limiting factor on capabilities.
This was not at all obvious in hindsight and if we survive the coming decades it will profoundly reshape every aspect of philosophy.
From an alignment perspective, the universality of deep learning independent of architecture is strong evidence for the natural abstraction hypothesis.
This is very good news! We have evidence that for any given data there is an ``objective'' ground truth.

\paragraph{Why might this be the case?}
Singular learning theory offers an information theoretic/thermodynamic explanation.

\paragraph{Problem}
The ground truth is data dependent. But this dependence gives us a leverage point for aligning AI models with human values and understanding.

\subsubsection{Denoising, compression, and clustering}
Ontologies must serve an information theoretic purpose.
I argue that their primary purpose is minimizing prediction loss through \textit{denoising}.
Which is to say, discarding information that cannot be used to make inferences.
I further posit that there are two mechanisms by which ontologies form: compression and clustering.

\paragraph{Compression}
I define ``compression'' as finding the most succinct representation of data that still retains the essential information necessary for accurate predictions or inferences.

\paragraph{Clustering}
``Clustering'' involves grouping similar concepts or data points, thereby simplifying the model's understanding and processing of the data.

These mechanisms are synergistic. Informally, I equate the two with PCA and SVD.
In my preliminary results, I hope to demonstrate that this intuition has (putative) empirical backing.

\subsection{Implications for ELK}
Explaining Like I'm 5 (ELK) becomes more feasible if models develop natural, easily decomposable ontologies, as it simplifies the process of translating complex concepts into simpler, more understandable terms.

\subsection{Aimability}
If ontologies are ``natural'', we should be able to more effectively guide AI development in a way that aligns with human values and understanding.

\subsubsection{Decomposing an ontology}
To ensure a powerful AI system's ontology aligns with human values, we must develop methods for effectively decomposing and understanding these ontologies.

% ... [remaining content] ...
